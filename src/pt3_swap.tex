\begin{frame}{Combinatorics}
\end{frame}

\begin{frame}{Descriptive Statistics}
\end{frame}

\begin{frame}{Hypothesis Testing}
\end{frame}

\begin{frame}{Regression Analysis}
\end{frame}


\begin{frame}{Introduction to Probability}
\end{frame}

\begin{frame}{Rules \& Axioms}
\end{frame}

\begin{frame}{Random Variables}
\end{frame}

\begin{frame}{Discrete Variables}
\end{frame}

\begin{frame}{Multivariate Random Variables}
\end{frame}

\begin{frame}{Joint Probability Distribution}
\end{frame}

\begin{frame}{Marginal Probability Distributions}
\end{frame}

\begin{frame}{Bayes’ Theorem}
\end{frame}

\begin{frame}{Independence}
\end{frame}

\begin{frame}{Continuous Multivariate Distributions}
\end{frame}

\begin{frame}{Expected Value}
\end{frame}

\begin{frame}{Variance}
\end{frame}

\begin{frame}{Bias-Variance Trade-off}
\url{http://d2l.ai/chapter_appendix-mathematics-for-deep-learning/statistics.html#the-bias-variance-trade-off}
\end{frame}


\begin{frame}{Covariance}
\end{frame}

\begin{frame}{Correlation}
\end{frame}

\begin{frame}{Covariance Matrix}
\end{frame}

\begin{frame}{Probability Distributions}
\end{frame}

\begin{frame}{Central Limit Theorem}
\end{frame}

\begin{frame}{Information Theory}
\end{frame}

\begin{frame}{Entropy}
\end{frame}

\begin{frame}{Cross-entropy}
\end{frame}

\begin{frame}{Kullback–Leibler Divergence}
\end{frame}

\begin{frame}{Maximum Likelihood Estimation}
\end{frame}

\begin{frame}{Maximum a Posteriori Estimation (MAP)}
\end{frame}

\begin{frame}{Principal Component Analysis}
\end{frame}

\begin{frame}{Sampling Methods}
\end{frame}
